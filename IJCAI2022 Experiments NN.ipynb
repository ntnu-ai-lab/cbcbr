{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from IPython.display import HTML\n",
    "import pyodbc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "casebase=list()\n",
    "#Function used retrieve relavant predictions for a given evaluation case. We call the prediction scores \"similarity\" for reusability reasons. \n",
    "#Prediction instances are filtered to ensure that they are relevant to the given case.\n",
    "def retrieve_c_att22(case):\n",
    "    global casebase\n",
    "    cases=casebase\n",
    "    cases=cases[cases[\"IndustrySubgroupCode\"].astype(float)==float(case[\"IndustrySubgroupCode\"])]\n",
    "    cases=cases[cases[\"MunicipalityNumber\"].astype(int)==int(case[\"MunicipalityNumber\"])]\n",
    "    results = cases.apply(pd.to_numeric, errors='coerce').fillna(cases).sort_values(by='similarity', ascending=False)\n",
    "    results['similarity'] = results['similarity'].astype(float)\n",
    "    results['NonCompliance'] = results['NonCompliance'].astype(int)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "casebase=list()\n",
    "initCBCopy=casebase\n",
    "currentCBCopy=casebase\n",
    "\n",
    "#Fill casebase in case its empty\n",
    "dataZero=()\n",
    "def readData():\n",
    "    global dataZero\n",
    "    cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=localhost;DATABASE=IJCAI2022;Trusted_Connection=yes;')\n",
    "    cursor = cnxn.cursor()\n",
    "    dataZero=pd.read_sql(\"SELECT  * \"+\"FROM [IJCAI2022].[dbo].[BayesianDynamicChecklistLocalDb]\"+\n",
    "                      \"left join (select NewID() as new, InspectionId as inspID from [IJCAI2022].[dbo].[BayesianDynamicChecklistLocalDb] group by InspectionId) as a on a.inspId=InspectionId\"+\n",
    "                      \" where InspectionDateId<20190601 ORDER BY new\",cnxn)\n",
    "    #Query selects items in random order (via the newID method), grouped by the inspectionIDs. \n",
    "    #We are doing crossvalidation with random split based on the indices of the randomly retrieved inspection ids. \n",
    "    #Thus, we are evaluating outcomes of inspections. This method also prevents data bleed/leakage.\n",
    "\n",
    "def FindBestParameters():\n",
    "    global casebase\n",
    "    global dataZero\n",
    "    # Specifying the ODBC driver, server name, database, etc. directly\n",
    "\n",
    "    cnxn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0};SERVER=localhost;DATABASE=IJCAI2022;Trusted_Connection=yes;')\n",
    "    cursor = cnxn.cursor()\n",
    "    data0=pd.read_sql(\"SELECT  * \"+\"FROM [IJCAI2022].[dbo].[BayesianDynamicChecklistLocalDb]\",cnxn)\n",
    "    data=pd.DataFrame(data={'NonCompliance':data0['NonCompliance'],'IndustrySubgroupCode':data0['IndustrySubgroupCode'],'ControlPointText': data0[\"ControlPointText\"],\"InspectionDateId\":data0[\"InspectionDateId\"],\"Municipality\":data0[\"Municipality\"]})\n",
    "    cat_vars=['ControlPointText','IndustrySubgroupCode',\"Municipality\"]\n",
    "    for var in cat_vars:\n",
    "        cat_list='var'+'_'+var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        #print(cat_list)\n",
    "        data1=data.join(cat_list)\n",
    "        data=data1\n",
    "         #checklist.loc[checklist[\"AntallBrudd\"]==-1,\"AntallBrudd\"]=0\n",
    "    cat_vars=['ControlPointText','IndustrySubgroupCode',\"Municipality\"]\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    #print(to_keep)\n",
    "    data=data[to_keep]\n",
    "    cat_vars=['NonCompliance']\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    data2=data[to_keep]\n",
    "\n",
    "\n",
    "    data.loc[np.isnan(data['NonCompliance']),\"NonCompliance\"]=0\n",
    "    data.loc[data['NonCompliance']<0,\"NonCompliance\"]=0\n",
    "    data.loc[data['NonCompliance']>1,\"NonCompliance\"]=1\n",
    "\n",
    "    y=data[\"NonCompliance\"]\n",
    "    data=data.drop(columns=[\"NonCompliance\"])\n",
    "\n",
    "    data=data.drop(columns=[\"InspectionDateId\"])\n",
    "    mlp_gs = MLPClassifier(max_iter=50)\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(10,),(20,),(50,),(100,)],\n",
    "        'activation': ['relu','logistic'],\n",
    "        'alpha': [0.0001, 0.05]\n",
    "    }\n",
    "    \n",
    "    clf = GridSearchCV(mlp_gs, parameter_space, n_jobs=2, cv=4)\n",
    "    clf.fit(data,y)\n",
    "\n",
    "    return clf\n",
    " \n",
    "    \n",
    "\n",
    "def fillCaseBase(index):\n",
    "    global casebase\n",
    "    global dataZero\n",
    "    # Specifying the ODBC driver, server name, database, etc. directly\n",
    "    data0=dataZero\n",
    "    data=pd.DataFrame(data={'NonCompliance':data0['NonCompliance'],'IndustrySubgroupCode':data0['IndustrySubgroupCode'],'ControlPointText': data0[\"ControlPointText\"],\"InspectionDateId\":data0[\"InspectionDateId\"],\"Municipality\":data0[\"Municipality\"]})\n",
    "    datatestout=data0.loc[round((len(data0)/8)*index):round((len(data0)/8)*(index+1))]\n",
    "    #Select independent variable and convert to one-hot vectors\n",
    "    cat_vars=['ControlPointText','IndustrySubgroupCode',\"Municipality\"]\n",
    "    for var in cat_vars:\n",
    "        cat_list='var'+'_'+var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data1=data.join(cat_list)\n",
    "        data=data1\n",
    "    cat_vars=['ControlPointText','IndustrySubgroupCode',\"Municipality\"]\n",
    "    data_vars=data.columns.values.tolist()\n",
    "    to_keep=[i for i in data_vars if i not in cat_vars]\n",
    "    data=data[to_keep]\n",
    "\n",
    "\n",
    "    #Making sure that the target variable is binary\n",
    "    data.loc[np.isnan(data['NonCompliance']),\"NonCompliance\"]=0\n",
    "    data.loc[data['NonCompliance']<0,\"NonCompliance\"]=0\n",
    "    data.loc[data['NonCompliance']>1,\"NonCompliance\"]=1\n",
    "\n",
    "    #retrieving the test-fold out of the 8 crossvalidation folds (rest are training folds.)\n",
    "    datatest=data.loc[round((len(data)/8)*index):round((len(data)/8)*(index+1))]\n",
    "    datatesty=datatest[\"NonCompliance\"]\n",
    "    datatest=datatest.drop(columns=[\"NonCompliance\"])\n",
    "    #Retrieving the 7 training folds, leaving the test-fold out.\n",
    "    datacp=data.copy()\n",
    "    if index>0 and index <7:                   \n",
    "        datacp=datacp.loc[0:round((len(datacp)/8)*index)-1]\n",
    "        datacp=datacp.append(data.loc[round((len(data)/8)*(index+1)):len(data)])\n",
    "    elif index<1:\n",
    "        datacp=datacp.loc[round((len(datacp)/8))*(index+1):len(datacp)]\n",
    "    else:\n",
    "        datacp=datacp.loc[0:round((len(data)/8)*index)]\n",
    "    \n",
    "    data=datacp\n",
    "    #Creating the target variable, dropping unwanted columns from the training set and training the model.    \n",
    "    y=data[\"NonCompliance\"]\n",
    "    data=data.drop(columns=[\"NonCompliance\"])\n",
    "    data=data.drop(columns=[\"InspectionDateId\"])\n",
    "    datatest=datatest.drop(columns=[\"InspectionDateId\"])\n",
    "    clf = MLPClassifier(activation='logistic', hidden_layer_sizes=(20,),alpha=0.0001,max_iter=100)\n",
    "    t=clf.fit(data,y)\n",
    "    #generate prediction for the test data set. The test data set is used to create and evaluate checklists below.\n",
    "    tes=clf.predict_proba(datatest)\n",
    "    tes=(datatestout).assign(similarity=tes[:,1]) #We named the prediction score \"similarity\" for easy reuse in other scripts.\n",
    "    tes=tes.assign(NonCompliance=datatesty)\n",
    "    casebase=tes #Test data set is assigned to \"casebase\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 214469.08248615265\n",
      "{'activation': 'logistic', 'alpha': 0.0001, 'hidden_layer_sizes': (20,)}\n",
      "MLPClassifier(activation='logistic', hidden_layer_sizes=(20,), max_iter=50)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf=FindBestParameters()\n",
    "traintime=traintime+(time.time()-start_time)\n",
    "print(\"Training time: \"+ str(traintime))\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)\n",
    "fh2=open(\"Log_\" + \"NNChecklistsBestParameters\"+ '.txt', 'w+')\n",
    "fh2.write(\"Training time: \"+ str(traintime))\n",
    "fh2.write(\"Best parameters:\"+ str(clf.best_params_))\n",
    "fh2.write(\"Best estimator:\"+ str(clf.best_estimator_))\n",
    "fh2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT, STATISTICS FOR GENERATED CHECKLISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "138939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12262.864439725876\n",
      "944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9401\n",
      "19030\n",
      "28295\n",
      "37591\n",
      "46953\n",
      "56085\n",
      "65396\n",
      "74848\n",
      "84197\n",
      "93589\n",
      "102919\n",
      "112240\n",
      "121465\n",
      "130658\n",
      "Current avg time:12830.108131885529\n",
      "Precision (gt): 0.2572581136860293\n",
      "Precision(val): 0.2905995349504363\n",
      "Precision: 0.2905995349504363\n",
      "Recall(val): 0.6819022720078182\n",
      "Recall: 0.6819022720078182\n",
      "Accuracy(val): 0.5243886898950308\n",
      "Accuracy: 0.5243886898950308\n",
      "Average number of control points per checklist(gt): 9.737238044062332\n",
      "Average number of control points per checklist: 14.250268672756583\n",
      "Average number of non-compliant control points per checklist(gt): 0.24402196947031876\n",
      "Average number of non-compliant control points per checklist(val): 4.202341105514333\n",
      "Average number of non-compliant control points per checklist: 4.202341105514333\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6833020673271807\n",
      "Average similarity: 0.2838827172708729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138939\n",
      "277878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12530.290630459785\n",
      "971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148302\n",
      "157969\n",
      "166907\n",
      "175988\n",
      "185323\n",
      "194698\n",
      "204186\n",
      "213882\n",
      "223042\n",
      "232448\n",
      "241653\n",
      "250747\n",
      "259899\n",
      "269053\n",
      "Current avg time:13096.317440271378\n",
      "Precision (gt): 0.25711664815148677\n",
      "Precision(val): 0.29051473010818973\n",
      "Precision: 0.29051473010818973\n",
      "Recall(val): 0.6858006358325665\n",
      "Recall: 0.6858006358325665\n",
      "Accuracy(val): 0.5206322662646964\n",
      "Accuracy: 0.5206322662646964\n",
      "Average number of control points per checklist(gt): 9.648811114079615\n",
      "Average number of control points per checklist: 14.172855997862676\n",
      "Average number of non-compliant control points per checklist(gt): 0.24303465165908633\n",
      "Average number of non-compliant control points per checklist(val): 4.173181461813473\n",
      "Average number of non-compliant control points per checklist: 4.173181461813473\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6807951139512526\n",
      "Average similarity: 0.2859854134628234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277878\n",
      "416816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12612.616060495377\n",
      "964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286694\n",
      "296138\n",
      "305186\n",
      "314684\n",
      "324140\n",
      "333702\n",
      "343133\n",
      "352589\n",
      "362086\n",
      "371035\n",
      "380392\n",
      "389757\n",
      "399299\n",
      "408667\n",
      "Current avg time:13133.242645661036\n",
      "Precision (gt): 0.2535781647016315\n",
      "Precision(val): 0.2836596695282049\n",
      "Precision: 0.2836596695282049\n",
      "Recall(val): 0.6884491655876447\n",
      "Recall: 0.6884491655876447\n",
      "Accuracy(val): 0.5225163521333075\n",
      "Accuracy: 0.5225163521333075\n",
      "Average number of control points per checklist(gt): 9.782118405155055\n",
      "Average number of control points per checklist: 14.21103503826017\n",
      "Average number of non-compliant control points per checklist(gt): 0.2411188267662312\n",
      "Average number of non-compliant control points per checklist(val): 4.081797237475254\n",
      "Average number of non-compliant control points per checklist: 4.081797237475254\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6883466530635379\n",
      "Average similarity: 0.2853856237109038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416816\n",
      "555755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12592.174218177795\n",
      "966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425949\n",
      "435293\n",
      "444632\n",
      "453914\n",
      "463145\n",
      "472535\n",
      "481779\n",
      "490910\n",
      "500135\n",
      "509500\n",
      "518525\n",
      "528088\n",
      "537510\n",
      "546681\n",
      "Current avg time:13107.056175291538\n",
      "Precision (gt): 0.2519243342858724\n",
      "Precision(val): 0.28377082461827524\n",
      "Precision: 0.28377082461827524\n",
      "Recall(val): 0.6912171172229014\n",
      "Recall: 0.6912171172229014\n",
      "Accuracy(val): 0.5162802674018667\n",
      "Accuracy: 0.5162802674018667\n",
      "Average number of control points per checklist(gt): 9.791527907286532\n",
      "Average number of control points per checklist: 14.207406420674037\n",
      "Average number of non-compliant control points per checklist(gt): 0.24115202693196738\n",
      "Average number of non-compliant control points per checklist(val): 4.087503197017904\n",
      "Average number of non-compliant control points per checklist: 4.087503197017904\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6891847545825325\n",
      "Average similarity: 0.2806198158596847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555755\n",
      "694694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12624.896219444276\n",
      "977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564941\n",
      "574079\n",
      "583594\n",
      "592591\n",
      "602070\n",
      "611362\n",
      "620548\n",
      "629859\n",
      "639234\n",
      "648639\n",
      "657848\n",
      "666961\n",
      "676410\n",
      "685834\n",
      "Current avg time:13123.53253312111\n",
      "Precision (gt): 0.2566672675842544\n",
      "Precision(val): 0.29637158910129396\n",
      "Precision: 0.29637158910129396\n",
      "Recall(val): 0.6822679705447489\n",
      "Recall: 0.6822679705447489\n",
      "Accuracy(val): 0.5255838566539912\n",
      "Accuracy: 0.5255838566539912\n",
      "Average number of control points per checklist(gt): 9.579509071504802\n",
      "Average number of control points per checklist: 14.154082177161152\n",
      "Average number of non-compliant control points per checklist(gt): 0.24252591466105572\n",
      "Average number of non-compliant control points per checklist(val): 4.26670069858479\n",
      "Average number of non-compliant control points per checklist: 4.26670069858479\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6768018548713937\n",
      "Average similarity: 0.28800364237722675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "694694\n",
      "833632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12653.887159744898\n",
      "983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703729\n",
      "713143\n",
      "722308\n",
      "731640\n",
      "740712\n",
      "749479\n",
      "758415\n",
      "767757\n",
      "776813\n",
      "786167\n",
      "795637\n",
      "805098\n",
      "814243\n",
      "823535\n",
      "832505\n",
      "Current avg time:13142.628243605295\n",
      "Precision (gt): 0.2561926546253888\n",
      "Precision(val): 0.2922806497264695\n",
      "Precision: 0.2922806497264695\n",
      "Recall(val): 0.6899872654209647\n",
      "Recall: 0.6899872654209647\n",
      "Accuracy(val): 0.5179638523895288\n",
      "Accuracy: 0.5179638523895288\n",
      "Average number of control points per checklist(gt): 9.718094232545862\n",
      "Average number of control points per checklist: 14.150191368615546\n",
      "Average number of non-compliant control points per checklist(gt): 0.24378369273446657\n",
      "Average number of non-compliant control points per checklist(val): 4.204289450627621\n",
      "Average number of non-compliant control points per checklist: 4.204289450627621\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6867818236084167\n",
      "Average similarity: 0.288262150311963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "833632\n",
      "972571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12666.040735040393\n",
      "978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843054\n",
      "852324\n",
      "861680\n",
      "871066\n",
      "879924\n",
      "889241\n",
      "898758\n",
      "908130\n",
      "917542\n",
      "927136\n",
      "936363\n",
      "945678\n",
      "955216\n",
      "964778\n",
      "Current avg time:13164.5820750509\n",
      "Precision (gt): 0.2543678931434775\n",
      "Precision(val): 0.28695824831217326\n",
      "Precision: 0.28695824831217326\n",
      "Recall(val): 0.6906393512317762\n",
      "Recall: 0.6906393512317762\n",
      "Accuracy(val): 0.5239936758833563\n",
      "Accuracy: 0.5239936758833563\n",
      "Average number of control points per checklist(gt): 9.710137133638074\n",
      "Average number of control points per checklist: 14.203011562247916\n",
      "Average number of non-compliant control points per checklist(gt): 0.24229584873911514\n",
      "Average number of non-compliant control points per checklist(val): 4.139444257134749\n",
      "Average number of non-compliant control points per checklist: 4.139444257134749\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6836674807368281\n",
      "Average similarity: 0.28587921242718267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n",
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "972571\n",
      "1111510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flogard_e\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current avg. training time:12671.418245702982\n",
      "969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-22a707626637>:51: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981668\n",
      "990870\n",
      "999821\n",
      "1008750\n",
      "1017812\n",
      "1026757\n",
      "1035910\n",
      "1045148\n",
      "1054309\n",
      "1063594\n",
      "1072893\n",
      "1081903\n",
      "1091378\n",
      "1100560\n",
      "1110012\n",
      "Current avg time:13181.992590785027\n",
      "Precision (gt): 0.25894127787994564\n",
      "Precision(val): 0.2864673392479684\n",
      "Precision: 0.2864673392479684\n",
      "Recall(val): 0.6867073193898997\n",
      "Recall: 0.6867073193898997\n",
      "Accuracy(val): 0.5195933865553424\n",
      "Accuracy: 0.5195933865553424\n",
      "Average number of control points per checklist(gt): 9.683774180813264\n",
      "Average number of control points per checklist: 14.132780629030135\n",
      "Average number of non-compliant control points per checklist(gt): 0.24834373380563807\n",
      "Average number of non-compliant control points per checklist(val): 4.110320161109689\n",
      "Average number of non-compliant control points per checklist: 4.110320161109689\n",
      "Percentage of control points in the intersection between the CBR generated and the original checklists: 0.6851994971832953\n",
      "Average similarity: 0.2828139821132096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "currentCBCopy=initCBCopy\n",
    "readData()\n",
    "timetotal=0\n",
    "traintime=0\n",
    "traintimetot=0\n",
    "precctot=0\n",
    "accctot=0\n",
    "preccgttot=0\n",
    "recctot=0\n",
    "fh2=open(\"Log_\" + \"NNChecklists\" + '.txt', 'w+')\n",
    "#for-loop to perform 8-fold crossvalidation. ik is used as an index for the validation folds.\n",
    "for ik in range(0,8):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    fillCaseBase(ik)\n",
    "    initCBCopy=casebase\n",
    "    currentCBCopy=initCBCopy\n",
    "\n",
    "    traintime=(time.time()-start_time)\n",
    "    traintimetot=traintimetot+(time.time()-start_time)\n",
    "    print(\"Train time: \"+str(traintime))\n",
    "    noncompliance=0 #true positive(for ground truth labels only)\n",
    "    controlpointsgtcount=0 \n",
    "    noncompliancengt=0 #true positive (for statistical estimates, see main paper)\n",
    "    controlpointscount=0 \n",
    "    truepositiveval=0\n",
    "    truepositive=0\n",
    "    falsepositivengt=0\n",
    "    recallval=0\n",
    "    accuracyval=0\n",
    "    precision=0\n",
    "    precisiongt=0\n",
    "    lengthprecgt=0\n",
    "    recall=0\n",
    "    accuracy=0\n",
    "    lengthprec=0.00001\n",
    "    lengthvalprec=0\n",
    "    lengthrec=0.00001\n",
    "    lengthvalrec=0\n",
    "    lengthacc=0.00001\n",
    "    lengthvalacc=0\n",
    "    truenegative=0\n",
    "    falsenegative=0\n",
    "    similarity=0\n",
    "    counter=0\n",
    "    Kcp=15\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    noncompliantInspection=0\n",
    "    inspections=casebase.drop_duplicates(subset = [\"InspectionId\"])\n",
    "    cases=casebase\n",
    "    cases[\"NonCompliance\"]=cases[\"NonCompliance\"].astype(int)\n",
    "    casestest=len(cases.drop_duplicates(subset = [\"ControlPointText\"]))\n",
    "    instanceMatches=list()\n",
    "    negatives=list()\n",
    "    inspectionstot=0\n",
    "    precchecklists=0\n",
    "    recchecklists=0\n",
    "    accchecklists=0\n",
    "    precchecklistsval=0\n",
    "    recchecklistsval=0\n",
    "    accchecklistsval=0\n",
    "    print(casestest)\n",
    "    #Iterate through all the past inspections in the data set. \n",
    "    #\"case\" contains a single inspection (which in practice consists of a set of instances in the data set).\n",
    "    for ind, case in inspections.iterrows():\n",
    "   \n",
    "        inspectionstot+=1\n",
    "        uniquechecklistlengthval=0\n",
    "        instanceMatches=list()\n",
    "        counter+=1\n",
    "        if counter>500:\n",
    "            counter=0\n",
    "            print(ind)\n",
    "            \n",
    "\n",
    "\n",
    "        #Retrieve the existing checklist. ExistingChecklist contains the checklist used in the current inspection.\n",
    "        existingChecklist=cases[cases['InspectionId']==case['InspectionId']]\n",
    "        #filter validation instances (cases) so that they match the industry code and municipality of the current inspection.\n",
    "        filteredCases=cases[cases[\"IndustrySubgroupCode\"].astype(float)==float(case[\"IndustrySubgroupCode\"])]\n",
    "        filteredCases=filteredCases[filteredCases[\"MunicipalityNumber\"].astype(int)==int(case[\"MunicipalityNumber\"])]\n",
    "        filteredCases[\"NonCompliance\"]=filteredCases[\"NonCompliance\"].astype(float)\n",
    "        #Temporary assigning the filtered cases. Another filter is applied further down to filter out positive cases.\n",
    "        negatives=filteredCases\n",
    "        if len(filteredCases)<=0:#Fail-safe mechanism. filteredCases should in practice never be 0.\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #Retrieve a constructed checklist\n",
    "        checklist=retrieve_c_att22(case)#Retrieve control points that matches each inspection (input case). checklist=CL from paper\n",
    "\n",
    "        #Drop any retrieved duplicates and remove select the top (Kcp) items with highest prediction score\n",
    "        uniqueChecklist=checklist.drop_duplicates(subset = [\"ControlPointText\"])#Find all unique control points by removing duplicates\n",
    "        uniqueChecklist=uniqueChecklist.head(Kcp)\n",
    "        if len(uniqueChecklist)>(0):#Safe check to make sure that somethingis on the checklist.\n",
    "            truepositive=0\n",
    "            truepositiveval=0\n",
    "            similarity+=uniqueChecklist[\"similarity\"].sum() #Sums prediction score (prediction score=similarity)\n",
    "            #Record statistics. sums up the ratio/fraction of non-compliance for each of the (unique) item in the checklist.\n",
    "            precpercl=0\n",
    "            lengthorgcl=0\n",
    "            #Iterate through all the items on a constructed checklist\n",
    "            for ind2, generatedChecklistControlpoint in uniqueChecklist.iterrows():#Find overlap between the existing and new generated checklist\n",
    "                #find the predicted negative records for the constructed checklist. uniqueChecklist contains all the predicted positives.\n",
    "                negatives=negatives[negatives[\"ControlPointText\"]!=generatedChecklistControlpoint[\"ControlPointText\"]]\n",
    "                #excp contains the items that can be found on both the existing checklist and the generated checklist\n",
    "                excp=existingChecklist[existingChecklist[\"ControlPointText\"]==generatedChecklistControlpoint[\"ControlPointText\"]]\n",
    "                #calculate ground truth precision for if excp contains an checklist item.\n",
    "                if len(excp)>0:\n",
    "                    precpercl+=((excp[\"NonCompliance\"].sum())/len(excp[\"NonCompliance\"])) #used to calculate average ground truth precision\n",
    "                    lengthorgcl+=1 #used to calculate average ground truth precision \n",
    "                    controlpointsgtcount+=1 #Used to find average number of items per checklist\n",
    "                controlpointscount+=1\n",
    "                #groups instances from the vaildation set by items and selects instances that matches the current item (generatedChecklistControlPoint)\n",
    "                instancesMatchingCurrentGenClItem=filteredCases.groupby([\"ControlPointText\"],as_index=False).mean()\n",
    "                instancesMatchingCurrentGenClItem=instancesMatchingCurrentGenClItem[instancesMatchingCurrentGenClItem[\"ControlPointText\"]==generatedChecklistControlpoint[\"ControlPointText\"]]\n",
    "                #Finds the total number of instances in the validation set with positive labels.\n",
    "                summ2=instancesMatchingCurrentGenClItem[\"NonCompliance\"].sum() \n",
    "                #Calculate the number of positive instances in the validation set (that matches the item), divided by the total number of instances.\n",
    "                #the expression summ2/len(instancesMatchingCurrentGenClItem[\"NonCompliance\"]) is a float-number between [0,1]\n",
    "                if len(instancesMatchingCurrentGenClItem[\"NonCompliance\"])>0:\n",
    "                    noncompliance+=(summ2/len(instancesMatchingCurrentGenClItem[\"NonCompliance\"]))\n",
    "                    truepositiveval+=(summ2/len(instancesMatchingCurrentGenClItem[\"NonCompliance\"]))\n",
    "                #test if there are at least 1 instance in the validation set that matches the current inspection and checklist item.\n",
    "                matchlen=len(instancesMatchingCurrentGenClItem[\"NonCompliance\"])\n",
    "                if matchlen>0:\n",
    "                    lengthvalprec+=1\n",
    "                    uniquechecklistlengthval+=1\n",
    "                \n",
    "                if matchlen==0:#expression is true if validation set record of checklist item does not exist. This expression never comes true for any method other than BCBR/CBCBR.\n",
    "                    instanceMatches=cases[cases[\"IndustrySubgroupCode\"].astype(float)==float(generatedChecklistControlpoint[\"IndustrySubgroupCode\"])]\n",
    "                    instanceMatches=instanceMatches[instanceMatches[\"MunicipalityNumber\"].astype(int)==int(generatedChecklistControlpoint[\"MunicipalityNumber\"])]\n",
    "                    instanceMatches=instanceMatches[instanceMatches[\"ControlPointText\"]==generatedChecklistControlpoint[\"ControlPointText\"]]\n",
    "                    instanceMatches[\"NonCompliance\"]=instanceMatches[\"NonCompliance\"].astype(float)\n",
    "\n",
    "                    matchesSum=instanceMatches[\"NonCompliance\"].sum()\n",
    "\n",
    "\n",
    "                    falsepositivengt+=(len(instanceMatches[\"NonCompliance\"])-matchesSum)\n",
    "                    if len(instanceMatches[\"NonCompliance\"])>0:\n",
    "                        noncompliancengt+=(matchesSum/len(instanceMatches[\"NonCompliance\"]))\n",
    "                        truepositive+=(matchesSum/len(instanceMatches[\"NonCompliance\"]))\n",
    "                        precision+=(matchesSum/len(instanceMatches[\"NonCompliance\"]))\n",
    "                        lengthprec+=1\n",
    "                #End of for-loop\n",
    "            if lengthorgcl>0:\n",
    "                precisiongt+=(precpercl/lengthorgcl)\n",
    "                lengthprecgt+=1      \n",
    "\n",
    "            #Calculate statistics on checklists level\n",
    "            uniquenegatives=len(negatives.drop_duplicates(subset = [\"ControlPointText\"]))\n",
    "            negativecpy=negatives.copy()\n",
    "            negativecpy[\"NonCompliance\"]=negativecpy[\"NonCompliance\"].astype(float)\n",
    "            groupedby=negativecpy.groupby([\"ControlPointText\"],as_index=False).count()\n",
    "            groupedbys=negativecpy.groupby([\"ControlPointText\"],as_index=False).sum()\n",
    "            groupedby[\"NonCompliance\"]=groupedbys[\"NonCompliance\"]/groupedby[\"NonCompliance\"]\n",
    "            uniquecalcnegatives=groupedby.drop_duplicates(subset = [\"ControlPointText\"])\n",
    "            noncompliancenegatives=uniquecalcnegatives[\"NonCompliance\"].sum()\n",
    "\n",
    "            falsenegativeelement=0\n",
    "            if uniquenegatives>0:\n",
    "                falsenegativeelement=noncompliancenegatives/uniquenegatives #To avoid selection bias effects\n",
    "            truenegativeelement=1-falsenegativeelement\n",
    "\n",
    "            truepositivesprchecklistval=(truepositiveval)\n",
    "            falsepositivesprchecklistval=(uniquechecklistlengthval-truepositivesprchecklistval)\n",
    "\n",
    "            truepositivesprchecklist=(truepositive+truepositiveval)\n",
    "            falsepositivesprchecklist=(len(uniqueChecklist)-(truepositive+truepositiveval))\n",
    "            truenegativesprchecklist=truenegativeelement*uniquenegatives\n",
    "            falsenegativesprchecklist=falsenegativeelement*uniquenegatives\n",
    "\n",
    "\n",
    "            precprchecklist=truepositivesprchecklist/len(uniqueChecklist)\n",
    "            precchecklists+=precprchecklist\n",
    "            precprchecklistval=0\n",
    "            if uniquechecklistlengthval>0:\n",
    "                precprchecklistval=truepositivesprchecklistval/uniquechecklistlengthval\n",
    "            precchecklistsval+=precprchecklistval\n",
    "\n",
    "            recprchecklist=0\n",
    "            if (truepositivesprchecklist+falsenegativesprchecklist)>0:\n",
    "                recprchecklist=truepositivesprchecklist/(truepositivesprchecklist+falsenegativesprchecklist)\n",
    "            recchecklists+=recprchecklist\n",
    "\n",
    "            recprchecklistval=0\n",
    "            if (truepositivesprchecklistval+falsenegativesprchecklist)>0:\n",
    "                recprchecklistval=truepositivesprchecklistval/(truepositivesprchecklistval+falsenegativesprchecklist)\n",
    "            recchecklistsval+=recprchecklistval\n",
    "\n",
    "            accprchecklist=0\n",
    "            if (len(uniqueChecklist)+uniquenegatives)>0:\n",
    "                accprchecklist=(truepositivesprchecklist+truenegativesprchecklist)/(len(uniqueChecklist)+uniquenegatives)\n",
    "            accchecklists+=accprchecklist\n",
    "\n",
    "            accprchecklistval=0\n",
    "            if (uniquechecklistlengthval+uniquenegatives)>0:\n",
    "                accprchecklistval=(truepositivesprchecklistval+truenegativesprchecklist)/(uniquechecklistlengthval+uniquenegatives)\n",
    "            accchecklistsval+=accprchecklistval\n",
    "\n",
    "            #|true positives for each checklist|=sum(true positive elements in checklist)\n",
    "            #|false positives for each checklist|=sum(false positive elements in checklist)\n",
    "            #|true negatives for each checklist|=|true unique negative elements not in checklist|\n",
    "            #|false negatives for each checklist|=|false unique negative elements not in checklist|\n",
    "        #End of inner for loop\n",
    "    #Recording statistics for the current cross-validation fold.\n",
    "    if inspectionstot>0:\n",
    "        precctot+=precchecklists/inspectionstot\n",
    "        accctot+=accchecklists/inspectionstot\n",
    "        preccgttot+=precisiongt/lengthprecgt\n",
    "        recctot+=recchecklists/inspectionstot\n",
    "    timetotal=timetotal+(time.time()-start_time)\n",
    "    print(\"Current avg time:\"+ str(timetotal/(ik+1)))\n",
    "    \n",
    "    print(\"Precision (gt): \"+str(precisiongt/lengthprecgt))\n",
    "    print(\"Precision: \"+str((precchecklists)/(inspectionstot)))\n",
    "    print(\"Recall: \"+str((recchecklists)/(inspectionstot)))\n",
    "    print(\"Accuracy: \"+str((accchecklists)/(inspectionstot)))\n",
    "    \n",
    "    #Additional information\n",
    "    print(\"Average number of items per checklist(gt): \"+str(controlpointsgtcount/inspectionstot))\n",
    "    print(\"Average number of items per checklist: \"+str((controlpointscount)/inspectionstot))\n",
    "    print(\"Average number of non-compliant items per checklist(gt): \"+str(precisiongt/inspectionstot))\n",
    "    print(\"Average number of non-compliant items per checklist: \"+str((noncompliance+noncompliancengt)/inspectionstot))\n",
    "\n",
    "    #number of common control points between CBR generated and original lists divided by the number of control points in the CBR generated list\n",
    "\n",
    "    print(\"Average similarity: \"+str(similarity/(lengthprecgt+lengthvalprec)))\n",
    "    print(\"\\nTrain time: \"+str(traintime))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nAverage Traintime: \"+str(traintimetot/8))                                \n",
    "print(\"\\nAverage Accuracy: \"+str(accctot/8))\n",
    "print(\"\\nAverage Prec: \"+str(precctot/8))\n",
    "print(\"\\nAverage Rec: \"+str(recctot/8))\n",
    "print(\"\\nAverage Precgt: \"+str(preccgttot/8))\n",
    "fh2.write(\"\\nAverage Traintime: \"+str(traintimetot/8))                                \n",
    "fh2.write(\"\\nAverage Accuracy: \"+str(accctot/8))\n",
    "fh2.write(\"\\nAverage Prec: \"+str(precctot/8))\n",
    "fh2.write(\"\\nAverage Rec: \"+str(recctot/8))\n",
    "fh2.write(\"\\nAverage Precgt: \"+str(preccgttot/8))\n",
    "fh2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
